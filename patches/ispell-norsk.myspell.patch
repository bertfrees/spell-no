--- ispell-3.2.06/languages/norsk/Makefile.my	2000-09-05 23:50:30.000000000 +0200
+++ ispell-3.2.06/languages/norsk/Makefile	2004-08-27 13:53:38.000000000 +0200
@@ -33,15 +33,13 @@
 
 # Some technical variables for managing hyphen points and the header
 
-# CATNOHEADER=sed -e '/^\#/ D' -e 's/[	]*\#.*//' ${LANGUAGE}.words
-CATNOHEADER=grep -v '^\#' ${LANGUAGE}.words
 ALPHASUBST=tr '-' 'î'
 STREKSUBST=tr 'î' '-'
 
 # What characters and flags do we use for Norwegian?
 
-LCH=\"a-zæøåéêèóôòçî
-UCH=A-ZÆØÅÉÊÈÓÔÒÇÎ
+LCH=\"abcdefghijklmnopqrstuvwxyzæøåéêèóôòçî
+UCH=ABCDEFGHIJKLMNOPQRSTUVWXYZÆØÅÉÊÈÓÔÒÇÎ
 CH=${LCH}${UCH}
 PRE=a-s
 SUFFNORM=][t-zA-Z^
@@ -116,8 +114,7 @@
 
 # In sum; It is nice if ispell can make a suggestion words like
 # `angrefrisperiode', but it consumes space and memory.
-
-COMPOUNDLIMIT=0
+COMPOUNDLIMIT=5
 
 # There is a system for selecting words to include in the Ispell
 # dictionary.  Unfortunately it is rather complex and not too easy to
@@ -219,6 +216,10 @@
 
 all: norsk.hash nynorsk.hash
 
+myspell: nb_NO.aff nb_NO.dic nn_NO.aff nn_NO.dic 
+
+myspell-dist: nb_NO.zip nn_NO.zip
+
 install: install-norsk install-nynorsk install-scripts
 
 install-norsk install-nynorsk: install-%: %.hash $(CONFIG)
@@ -269,7 +270,48 @@
 	echo -e 'suffixes\nflag *z:\nY Y Y Y Y   >   YYYYYY' >> $@
 
 norsk.words: norsk.words.sq
-	unsq < norsk.words.sq > norsk.words
+	PATH=$(PATHADDER):$$PATH; \
+	export PATH; unsq < norsk.words.sq > norsk.words
+
+# MySpell support (6 Jun 2002, 26 Apr 2004 toralf@procaptura.com)
+# *** FIXME: Also generate "TRY" line
+define ISPELL2MYAFF
+	echo "SET ISO8859-1" > $@
+	echo "TRY aerndtislogmkpbhfjuvæøåyqxzvcwéèóôôçîAERNDTISLOGMKPBHFJUVÆØÅYQXZVCWÉÈÓÔÔÇ" >> $@
+	perl iaff2myaff.pl $< >> $@
+endef
+
+nb_NO.aff: norsk.aff
+	$(ISPELL2MYAFF)
+
+nn_NO.aff: nynorsk.aff
+	$(ISPELL2MYAFF)
+
+# Note: mch.cnt is secondary output from buildhash
+norsk.mch.cnt nynorsk.mch.cnt: %.mch.cnt: %.hash
+
+nb_NO.dic: norsk.mch.cnt norsk.mch
+	cat $^ > $@
+
+nn_NO.dic: nynorsk.mch.cnt nynorsk.mch
+	cat $^ > $@
+
+README_%.txt: README.myspell
+	cp $< $@
+
+%.zip: %.dic %.aff README_%.txt
+	zip $@ $^
+
+# Create a "clean" version of wordlist, i.e. one that has no comments, blank
+# lines, trailing whitespace etc., and that is resorted. This saves us from
+# calling sed etc. to filter the wordlist every time it is used (like the
+# original version did) and it is also a good idea to make sure list is sorted
+# in exactly the same way as generated files, 'join' command will otherwise
+# work incorrectly.
+# *** Hack: Do tricks here to include some missing words...
+
+%.words.plain: %.words
+	(sed -e "s/#.*//" -e "s/^å .*/å * 31 B/" -e "s/[[:space:]]*$$//" $< | egrep -v "^$$"; echo "i * 31 B") | sort > $@
 
 # The following ugly code munches a part of the base file, keeping the
 # indications of the frequency of the words.  It also removes some
@@ -277,7 +319,6 @@
 # improved.
 
 
-munched.%: norsk.words norsk.aff.munch norsk.munch.hash
 # The first pipe produces a list of all words in the % category, with
 # each root word followed by one line for each flag containing the
 # root word and the flag.  The prefix flags are treated as part of the
@@ -287,65 +328,44 @@
 # Isn't it amazing how much you can do with sed?
 
 # If we try to munch the whole B dictionary in one run, ispell will
-# probably dump core.  This happens when one gets `hash overflows'.
-# Check the log, and change the splitting (^[${UCH}]) if nessesary.
-# Nasty bug, and very silent.
-	PATH=$(PATHADDER):$$PATH; \
+# probably dump core.  Nasty bug, and very silent
+# Munch one starting character at a time to avoid this
+munch1.%: ${LANGUAGE}.words.plain ${AFFIXES}.munch ${LANGUAGE}.munch.hash 
+	cat /dev/null > $@
+	@PATH=$(PATHADDER):$$PATH; \
 	export PATH; \
-	${CATNOHEADER} \
-	  | grep -e '$(subst munched.,,$@)$$' \
+	for l in `echo ${CH} | sed "s/./& /g"`; do \
+	  echo "[$<, flag $*, words '$$l.*'] | munchlist -l ${AFFIXES}.munch >> $@"; \
+	  egrep "^$$l.*$*$$" $< \
 	  | sed -e 's/ .*//' -e 's/-/î/g' -e 's/ \*//' \
-	  | grep '^[${UCH}]' \
-	  | munchlist -v -l ${AFFIXES}.munch \
-	  > munch1.tmp
-	PATH=$(PATHADDER):$$PATH; \
-	export PATH; \
-	${CATNOHEADER} \
-	  | grep -e '$(subst munched.,,$@)$$' \
-	  | sed -e 's/ .*//' -e 's/-/î/g' -e 's/ \*//' \
-	  | grep -v '^[${UCH}]' \
-	  | munchlist -v -l ${AFFIXES}.munch \
-	  >> munch1.tmp
-	cat munch1.tmp \
-	  | sed -e 's/\(zyzyzy\|ZYZYZY\)/\1\/\` /' \
-	  | sed -e 's/^\(.*\)$$/----\1\*\1/' | tr '*' '\n' \
-	  | sed -e '/----/ s/î//g' \
-	  | sed -e N -e 's/\n/ ----/' \
-	  | sort  '-t/' -u +0f -1 +0 \
-	  | sed -e 's/.*----//' \
-	  | sed -e 's/\(et\/.*T.*\)V/\1/' \
-		-e 's/\(e\/.*T.*\)W/\1/' \
-		-e 's/\(er\/.*I.*\)V/\1/' \
-		-e 's/\(e\/.*B.*\)W/\1/' \
-		-e 's/\([^ei]um\/.*B.*\)I/\1/' \
-	  | sed -e N -e 's/^\(\([-${CH}]\)*\([^e][^r]\|[e][^r]\|[r][^e]\)\)\/\([A-Zt-z]*\)\n\1e\/\([A-Zt-z]*\)R\([A-Zt-z]*\)$$/\1\/\4\*\1e\/\5\6/g' \
-		 -e '$$ p' -e '$$ d' -e P -e D \
-	  | tr '*' '\n' \
-	  | sed -e N -e 's/^\(\([-${CH}]\)*\)\(\/[AB]*\)E\(.*\)\n\1er\/AI/\1\3\4\*\1er\/AI/' \
-		-e '$$ p' -e '$$ d' -e P -e D \
-	  | tr '*' '\n' \
-	  | ${STREKSUBST} \
-	  | sed -e 's/\/\([${SUFF}]*\)\([${PRE}]*\)/\/\2\1/' \
-		-e 's/\(\([-${CH}]\)*\)\/\([${PRE}]*\)\([${SUFF}]\+\)$$/\1\/\3\*\1\/\3\4/' \
-		-e 's/^\([-${CH}]*\)$$/\1\/ /' \
-	  | tr '*' '\n' \
-	  | sed -e ':START' \
-		-e 's/^\([-${CH}]\+\)\/\([${PRE}]*\)\([${SUFF}]\+\)\([${SUFF}]\)/\1\/\2\3\*\1\/\2\4/' \
-		-e 't START' \
-		-e 's/^\([-${CH}]\+\)\/\([${PRE}]\+\)\(\*\|$$\)/\1\/\*\1\/\2\3/'\
-	  |  tr '*' '\n' > munch2.tmp
-# This pipe produce a file containing the a line number of munch2.tmp and
+	  | munchlist -l ${AFFIXES}.munch >> $@ ; \
+	done
+
+munch2.%: munch1.%
+	perl expndflg.pl $< | sort  '-t/' -u +0f -1 +0 > $@
+
+
+# *** Mulige problemer:
+#     /R og /E slettet en del flere steder en med gammel versjon. Det ser ut
+#     for meg som om det er riktig å fjerne flaggene på alle disse stedene.
+#     
+#     <ord>/ak ekspanderes til <ord>/a og <ord>/k, men *kanskje* er det riktig
+#     å beholde <ord>/ak
+
+munch3.%: munch2.% ${LANGUAGE}.words.plain ${LANGUAGE}.munch.hash
+# This pipe produce a file containing the a line number of munch2 and
 # the frequency indicator for that line.  Note that the summation rule
 # is not the usual one.
-	PATH=$(PATHADDER):$$PATH; \
+	@echo "cat $< | [ Get line no and frequency ] > $@"
+	@PATH=$(PATHADDER):$$PATH; \
 	export PATH; \
-	cat munch2.tmp \
+	cat $< \
 	  | tr -d ' ' \
 	  | ispell -e -d ./${LANGUAGE}.munch.hash \
 	  | sed -e 's/^[-${CH}]\+ //' -e 's/î/-/g' \
 	  | awk --source '{i=0; while (i<NF) {i=i+1;print $$i,NR}}' \
 	  | sort \
-	  | join - ${LANGUAGE}.words \
+	  | join - ${LANGUAGE}.words.plain \
 	  | sed -e 's/\* //' \
 	  | cut -d ' ' -f2,3 \
 	  | sort -n \
@@ -360,15 +380,18 @@
 		if ($$i<5) {s=s+$$i} else {s = s + exp(exp(($$i+9)/15)-1)}}};\
 		if (s<=5) {t=s} else {t=-9+15*log(1+log(s))};\
 		print $$1, int(t)}' \
-	  > munch3.tmp
-# This pipe produce the file containing the munched list of words,
+	  > $@
+
+munched.%: munch2.% munch3.%
+# This pipe produces the file containing the munched list of words,
 # where the rare words we don't want are removed.  What we don't want
 # depends on the category of words, and is defined at the start of
 # this Makefile.
-	cat -n munch2.tmp \
-	  | join - munch3.tmp \
+	@echo "Collect data from $^ in $@"
+	@cat -n munch2.$* \
+	  | join - munch3.$* \
 	  | cut -d ' ' -f2,3 \
-	  | awk --re-interval --source ${$(subst munched.,CHOOSEFLAG,$@)} \
+	  | awk --re-interval --source ${CHOOSEFLAG$*} \
 	  | uniq \
 	  | tr -d ' ' \
 	  | sed -e '$$ p' -e '$$ D' -e ':START' -e '$$ ! N' \
@@ -387,62 +410,71 @@
 		if ($$i<5) {s=s+$$i} else {s = s + exp(exp(($$i+9)/15)-1)}}};\
 		if (s<=5) {t=s} else {t=-9+15*log(1+log(s))};\
 		print $$1, int(t)}' \
-	  | awk --re-interval --source ${$(subst munched.,CHOOSEROOT,$@)} \
+	  | awk --re-interval --source ${CHOOSEROOT$*} \
 	  | uniq \
 	  > $@
-#	Comment out the next line if you are debugging.
-	rm munch[123].tmp
 
-
-norsk.mch: forkort.txt $(patsubst %,munched.%,${CATHEGORIES}) $(AFFIXES)
 # Here we make the dictionary that is read by the ispell's builhash
 # program.  The main difficulty is to delete compound words with
 # frequency indicator less than COMPOUNDLIMIT accepted in controlled
 # compoundwords mode.
 
+%.comp1.mch: %.aff forkort.txt $(addprefix munched.,${CATHEGORIES})
 # First make a list of words with some compound flag, and a hash-file.
-	cat forkort.txt $(patsubst %,munched.%,${CATHEGORIES}) \
+	cat $(filter-out %.aff,$^) \
 	  | tr -d '\-0-9 ' \
 	  | grep "\/.*[z\\_\`]" \
-	  > comp1.tmp
-	$(BUILDHASH) comp1.tmp $(AFFIXES) comp.hash
+	  > $@
+
+%.comp.hash: %.comp1.mch
+	$(BUILDHASH) $< $(AFFIXES) $@
 
 # Make a list of candidates to be removed.  Exclude all words with
 # compound flags and those with frequency indicator bigger than
 # COMPOUNDLIMIT.  This could be improved.  One could insist that the
 # words forming a word that should be deleted are separated by a
 # hyphen at the correct point.  That would complicate things.
-
-	cat -n forkort.txt $(patsubst %,munched.%,${CATHEGORIES}) \
+%.comp2.mch: %.aff forkort.txt $(addprefix munched.,${CATHEGORIES})
+	cat -n $(filter-out %.aff,$^) \
 	  | grep -v "\/.*[z\\_\`]" \
 	  | awk --source '/-/ {if ($$3<${COMPOUNDLIMIT}) {print $$1,$$2,$$3}}' \
-	  > comp2.tmp
+	  > $@
+
 # Test which words are accepted by ispell.  Output is a list of line
 # numbers indicating the lines that can be removed from the munched
 # file.
+%.comp3.mch: %.comp2.mch %.comp.hash
 	PATH=$(PATHADDER):$$PATH; \
 	export PATH; \
-	cat comp2.tmp \
+	cat $< \
 	  | tr -d '\-0-9 ' \
-	  | ispell -e -d ./comp.hash \
+	  | ispell -e -d ./$*.comp.hash \
 	  | sed -e 's/$$/ xyxyxyxy/' \
-	  | ispell -l -d ./comp.hash \
+	  | ispell -l -d ./$*.comp.hash \
 	  | sed -e 's/xyxyxyxy/î/' \
 	  | tr '\nî' ' \n' \
-	  | paste comp2.tmp - \
+	  | paste $< - \
 	  | grep '	 $$' \
 	  | sed -e 's/ .*//' \
-	  > comp3.tmp
-	@echo Removing `cat comp3.tmp | wc -l` compound root words
+	  > $@
 # Remove all the line numbers that is found twice, and all words
 # containing xxxx and yyyy.  Those words didn't fit in in the munching,
 # and since it is few words I don't want to fiddle with them.
-	cat -n forkort.txt $(patsubst %,munched.%,${CATHEGORIES}) \
-	  | sort -n -m -s +0 -1  comp3.tmp - \
+
+norsk.mch: %.mch : %.comp3.mch forkort.txt $(addprefix munched.,${CATHEGORIES})
+	@echo Removing `cat $< | wc -l` compound root words
+	cat -n $(filter-out %.mch,$^) \
+	  | sort -n -m -s +0 -1 $< - \
 	  | sed -e '/^[0-9]\+$$/,/.*/ D' -e '/\(xxxx\|yyyy\)\// D' \
 	  | tr -d '\- 	0-9' \
 	  > $@
-	rm -f comp.hash comp[123].tmp*
+
+
+# Keep some of the  intermediate files from the above process to make
+# debugging easier, and because some of the steps take a LONG time
+.PRECIOUS: munch1.% munch2.% munch3.% %.comp1.mch %.comp2.mch %.comp3.mch
+
+
 
 # TODO:
 # If a rare word lies close to a common word, it might be wise to
@@ -456,11 +488,10 @@
 
 
 
-nynorsk.mch: norsk.words ny${AFFIXES}.munch
+nynorsk.mch: norsk.words.plain ny${AFFIXES}.munch
 	PATH=$(PATHADDER):$$PATH; \
 	export PATH; \
-	${CATNOHEADER} \
-	  | grep '\*' \
+	grep '\*' < $< \
 	  | sed -e 's/ .*//' \
 	  | tr -d '-' \
 	  | munchlist -v -l ny${AFFIXES}.munch \
@@ -468,13 +499,12 @@
 		-e '$$ p' -e '$$ d' -e P -e D \
 	  > $@ 
 
-words.norsk: norsk.words
+words.norsk: norsk.words.plain
 # Here is a rule to make a list of the most common Norwegian words.
 # Which words to include is defined at the top of this Makefile.  Such
 # a file is needed to make the word competition work for Norwegian.
 # Stupid spell checkers might also want such a file.
-	${CATNOHEADER} \
-	  | grep '[BANDS]$$' \
+	grep '[BANDS]$$' < $< \
 	  | tr -d '*' \
 	  | awk --re-interval --source ${WORDSFILTER} \
 	  | tr -d '\"-' \
@@ -482,19 +512,17 @@
 	  | sort -f \
 	  > $@
 
-words.nynorsk: norsk.words
+words.nynorsk: norsk.words.plain
 # No frequency information availiable yet for nynorsk.  So all we can
 # do is poick the words marked with a star.
-	${CATNOHEADER} \
-	  | grep '\*' \
+	grep '\*' < $<\
 	  | sed -e 's/ .*//' \
 	  > $@ 
 
 # Here is a target that picks words with given frequency.
-words.${LANGUAGE}.%: ${LANGUAGE}.words
-	${CATNOHEADER} \
-	  | grep '[BANDS]$$' \
-	  | grep  ' $(patsubst words.${LANGUAGE}.%,%,$@) ' \
+words.${LANGUAGE}.%: ${LANGUAGE}.words.plain
+	grep '[BANDS]$$' < $< \
+	  | grep  ' $* ' \
 	  | sed -e 's/ .*//' \
 	  | tr -d - \
 	  | grep -v '\(xxxx\|yyyy\|zyzyzy\)' \
@@ -505,11 +533,11 @@
 unpack:	norsk.words
 
 clean:
-	rm -f core *.hash *.stat *.cnt munch[123].tmp \
+	rm -f core *.hash *.stat *.cnt munch[123].* \
 	      ${DICTIONARY} ny${DICTIONARY} \
 	      ${AFFIXES} ny${AFFIXES} \
 	      ${AFFIXES}.munch ny${AFFIXES}.munch \
-	      comp[123].tmp*
+	      *.comp[123].* *myspell* munched.* core*
 
 #	The following target is used in the English makefile, and is
 #	required to be present in all other language Makefiles as
--- ispell-3.2.06/languages/norsk/iaff2myaff.pl.my	2004-08-26 13:23:08.000000000 +0200
+++ ispell-3.2.06/languages/norsk/iaff2myaff.pl	2004-04-26 12:54:24.000000000 +0200
@@ -0,0 +1,88 @@
+#!/usr/bin/perl
+use locale;			# For lc() to handle non-ASCII charcters
+
+foreach $fileName (@ARGV) {
+    open(FILE, $fileName);
+    while(chop($line=<FILE>)) {
+	$line=~s/#.*//;		# Strip comments
+	if($typeId && $line=~m/flag/) {
+	    ($id, $combine, $compound, @rewrite)=parseFlag(\*FILE, $line);
+	    
+	    if($compound) {
+		print STDERR ("Warning: Compound affix \"$typeId $id\"",
+			      " commented out in output.\n");
+		
+		print("\n# *** FIXME: The following rule set is applicable\n");
+		print("#            to compounds only:\n");
+		print("# ", $typeId, " ", $id, " ", ($combine?"Y":"N"), " ",
+		      $#rewrite+1, "\n");
+		foreach $r (@rewrite) {
+		    print("# ", $typeId, " ", $id, "   ", $r, "\n");
+		}
+	    } else {
+		if($#rewrite<0) {
+		    print STDERR ("Warning: No entries found for", 
+				  " \"$typeId $id\"; affix skipped.\n");
+		} else {
+		    print("\n", $typeId, " ", $id, " ", ($combine?"Y":"N"), " ",
+			  $#rewrite+1, "\n");
+		    foreach $r (@rewrite) {
+			print($typeId, " ", $id, "   ", $r, "\n");
+		    }
+		}
+	    }
+	} elsif($line=~m/suffixes/) {
+	    $typeId="SFX";
+	} elsif($line=~m/prefixes/) {
+	    $typeId="PFX";
+	} elsif($line=~m/compoundwords/) {
+	    ($compundFlag)=($line=~m/controlled\s*([A-Za-z])/);
+	    print("\nCOMPOUNDFLAG ", $compundFlag, "\n") if($compundFlag);
+	} elsif($line=~m/compoundmin/) {
+	    ($compundMin)=($line=~m/compoundmin\s*([0-9]+)/);
+	    print("\nCOMPOUNDMIN ", $compundMin, "\n") if($compundMin);
+	}
+    }
+    close(FILE, $fileName);
+}
+
+sub parseFlag {
+    my($fileRef, $line)=@_;
+    my($id, $comb, $comp, @rules)=("A", 0, 0);
+
+    $comb=1 if($line=~m/\*/);
+    $comp=1 if($line=~m/~/);
+    ($id)=($line=~m/flag.*(.)\s*:/);
+    
+    # Skip initial comments/blank lines...
+    while(chop($line=<$fileRef>) && $line=~m/^\s*(\#|$)/) { 
+    }
+
+    while($line=~m/>/) {
+	my($from, $to, $remove, $add);
+
+	$line=~s/#.*//;
+	$line=~s/\s//g;
+	$line=~s/Î//g;		# ***
+	$line=lc($line);
+
+	
+	($from, $to)=split('>', $line);
+	($remove, $add)=($to=~m/-([^,]*),(.*)/);
+	if(!$remove) {
+	    $remove="0";
+	    $add=$to;
+	}
+	if(!$add || $add eq "-") {
+	    $add="0";
+	}
+	push(@rules, "$remove  $add  $from");
+	do {
+	    chop($line=<$fileRef>);
+	} while($line && $line=~m/^\s*#/); # Handle lines "commented out" etc.
+    }
+    
+    
+    return ($id, $comb, $comp, @rules);
+}
+
--- ispell-3.2.06/languages/norsk/expndflg.pl.my	2004-08-26 13:25:45.000000000 +0200
+++ ispell-3.2.06/languages/norsk/expndflg.pl	2004-08-27 13:32:56.000000000 +0200
@@ -0,0 +1,57 @@
+#!/usr/bin/perl
+# Purpose: Expand list so that there is one line for each word/flag character 
+#          combination, and remove combinations that would lead to redundancies
+# Remarks: This script is reverse-engineered from old, slow and messy sed/awk
+#          commands in Makefile for "ispell norsk"
+
+foreach $fileName (@ARGV) {
+    open(FILE, $fileName);
+
+    chop($line=<FILE>);
+    $line=~tr/î/-/ if($line);
+    
+    while($line) {
+	chop($nextLine=<FILE>);
+	$nextLine=~tr/î/-/ if($nextLine);
+
+	$line=~s/(e(t\/.*T.*|r\/.*I.*))V/$1/;
+	$line=~s/(e\/.*[TB].*)W/$1/;
+	$line=~s/([^ei]um\/.*B.*)I/$1/;
+	
+	my($word, $flags)=split('/', $line);
+	
+	$flags=~s/^(.*[AB]|)E/$1/ if($nextLine=~m/^${word}er\/AI/);
+	
+	if(!$flags) {
+	    # Note: Old sed scripts would print an extra ' ' after '/' in this
+	    #       case; this may or may not be necessary
+	    print($word, "/");
+	    print("`") if($word=~m/zyzyzy$/);
+	    print(" \n");
+	} else {
+	    print($word, "/\n");
+	    
+	    # Note: The below 'm' operator will return $flags a list of letters
+	    #       in $flags, as with 'g' a list if every possible match is
+	    #       returned, and '.' matches any single character.
+	    foreach $flag (($flags=~m/./g)) {
+		print($word, "/");
+		
+		if(!($flag=~m/[a-s]/g)) {
+		    foreach $prefix (($flags=~m/[a-s]/g)) {
+			print($prefix);
+		    }
+		}
+		print($flag, "\n");
+	    }
+
+	    if($flags=~m/[A-Zt-z]/ && !($word=~m/(re|er)$/)) {
+		$nextLine=~s/(${word}e\/.*)R/$1/;
+		$nextLine=~s/\/$//; # Remove separator if no flags are left
+	    }
+	}
+	
+        $line=$nextLine;
+    }
+    close(FILE);
+}
