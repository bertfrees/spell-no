--- ispell-3.2.06/languages/norsk/Makefile.my	2000-09-05 23:50:30.000000000 +0200
+++ ispell-3.2.06/languages/norsk/Makefile	2003-09-24 10:58:28.000000000 +0200
@@ -16,6 +16,7 @@
 # numerous languages.
 #
 LANGUAGE	=	norsk
+LANGUAGE_CODE	=	no_NO
 DICTIONARY	=	$(LANGUAGE).mch
 HASHFILE	=	$(LANGUAGE).hash
 
@@ -33,15 +34,13 @@
 
 # Some technical variables for managing hyphen points and the header
 
-# CATNOHEADER=sed -e '/^\#/ D' -e 's/[	]*\#.*//' ${LANGUAGE}.words
-CATNOHEADER=grep -v '^\#' ${LANGUAGE}.words
 ALPHASUBST=tr '-' 'î'
 STREKSUBST=tr 'î' '-'
 
 # What characters and flags do we use for Norwegian?
 
-LCH=\"a-zæøåéêèóôòçî
-UCH=A-ZÆØÅÉÊÈÓÔÒÇÎ
+LCH=\"abcdefghijklmnopqrstuvwxyzæøåéêèóôòçî
+UCH=ABCDEFGHIJKLMNOPQRSTUVWXYZÆØÅÉÊÈÓÔÒÇÎ
 CH=${LCH}${UCH}
 PRE=a-s
 SUFFNORM=][t-zA-Z^
@@ -116,8 +115,7 @@
 
 # In sum; It is nice if ispell can make a suggestion words like
 # `angrefrisperiode', but it consumes space and memory.
-
-COMPOUNDLIMIT=0
+COMPOUNDLIMIT=5
 
 # There is a system for selecting words to include in the Ispell
 # dictionary.  Unfortunately it is rather complex and not too easy to
@@ -219,6 +217,10 @@
 
 all: norsk.hash nynorsk.hash
 
+myspell: norsk-myspell.aff norsk-myspell.dic nynorsk-myspell.aff nynorsk-myspell.dic 
+
+myspell-dist: $(LANGUAGE_CODE).zip
+
 install: install-norsk install-nynorsk install-scripts
 
 install-norsk install-nynorsk: install-%: %.hash $(CONFIG)
@@ -269,7 +271,47 @@
 	echo -e 'suffixes\nflag *z:\nY Y Y Y Y   >   YYYYYY' >> $@
 
 norsk.words: norsk.words.sq
-	unsq < norsk.words.sq > norsk.words
+	PATH=$(PATHADDER):$$PATH; \
+	export PATH; unsq < norsk.words.sq > norsk.words
+
+# MySpell support (6 Jun 2002, toralf@kscanners.com)
+# *** FIXME: Also generate "TRY" line
+%-myspell.aff: %.aff
+	echo "SET ISO8859-1" > $@
+	echo "TRY aerndtislogmkpbhfjuvæøåyqxzvcwéèóôôçîAERNDTISLOGMKPBHFJUVÆØÅYQXZVCWÉÈÓÔÔÇ" >> $@
+	perl iaff2myaff.perl $< >> $@
+
+# Note: mch.cnt is secondary output from buildhash
+norsk.mch.cnt nynorsk.mch.cnt: %.mch.cnt: %.hash
+
+norsk-myspell.dic nynorsk-myspell.dic: %-myspell.dic : %.mch.cnt %.mch 
+	cat $^ > $@
+
+
+$(LANGUAGE_CODE).zip: $(LANGUAGE_CODE)
+	zip -r -j $@ $<
+
+
+
+$(LANGUAGE_CODE): $(LANGUAGE)-myspell.aff $(LANGUAGE)-myspell.dic ny$(LANGUAGE)-myspell.aff ny$(LANGUAGE)-myspell.dic README.myspell
+	install -d -m 775 $@
+	install -m 444 $(LANGUAGE)-myspell.aff $@/$@.aff
+	install -m 444 $(LANGUAGE)-myspell.dic $@/$@.dic
+	install -m 444 ny$(LANGUAGE)-myspell.aff $@/$(subst no,nn,$@).aff
+	install -m 444 ny$(LANGUAGE)-myspell.dic $@/$(subst no,nn,$@).dic
+	install -m 444 README.myspell $@/README_$@.txt
+
+
+# Create a "clean" version of wordlist, i.e. one that has no comments, blank
+# lines, trailing whitespace etc., and that is resorted. This saves us from
+# calling sed etc. to filter the wordlist every time it is used (like the
+# original version did) and it is also a good idea to make sure list is sorted
+# in exactly the same way as generated files, 'join' command will otherwise
+# work incorrectly.
+# *** Hack: Do tricks here to include some missing words...
+
+%.words.plain: %.words
+	(sed -e "s/#.*//" -e "s/^å .*/å * 31 B/" -e "s/[[:space:]]*$$//" $< | egrep -v "^$$"; echo "i * 31 B") | sort > $@
 
 # The following ugly code munches a part of the base file, keeping the
 # indications of the frequency of the words.  It also removes some
@@ -277,7 +319,6 @@
 # improved.
 
 
-munched.%: norsk.words norsk.aff.munch norsk.munch.hash
 # The first pipe produces a list of all words in the % category, with
 # each root word followed by one line for each flag containing the
 # root word and the flag.  The prefix flags are treated as part of the
@@ -287,26 +328,22 @@
 # Isn't it amazing how much you can do with sed?
 
 # If we try to munch the whole B dictionary in one run, ispell will
-# probably dump core.  This happens when one gets `hash overflows'.
-# Check the log, and change the splitting (^[${UCH}]) if nessesary.
-# Nasty bug, and very silent.
-	PATH=$(PATHADDER):$$PATH; \
-	export PATH; \
-	${CATNOHEADER} \
-	  | grep -e '$(subst munched.,,$@)$$' \
-	  | sed -e 's/ .*//' -e 's/-/î/g' -e 's/ \*//' \
-	  | grep '^[${UCH}]' \
-	  | munchlist -v -l ${AFFIXES}.munch \
-	  > munch1.tmp
-	PATH=$(PATHADDER):$$PATH; \
+# probably dump core.  Nasty bug, and very silent
+# Munch one starting character at a time to avoid this
+munch1.%: ${LANGUAGE}.words.plain ${AFFIXES}.munch ${LANGUAGE}.munch.hash 
+	cat /dev/null > $@
+	@PATH=$(PATHADDER):$$PATH; \
 	export PATH; \
-	${CATNOHEADER} \
-	  | grep -e '$(subst munched.,,$@)$$' \
+	for l in `echo ${CH} | sed "s/./& /g"`; do \
+	  echo "[$<, flag $*, words '$$l.*'] | munchlist -l ${AFFIXES}.munch >> $@"; \
+	  egrep "^$$l.*$*$$" $< \
 	  | sed -e 's/ .*//' -e 's/-/î/g' -e 's/ \*//' \
-	  | grep -v '^[${UCH}]' \
-	  | munchlist -v -l ${AFFIXES}.munch \
-	  >> munch1.tmp
-	cat munch1.tmp \
+	  | munchlist -l ${AFFIXES}.munch >> $@ ; \
+	done
+
+munch2.%: munch1.%
+	@echo "cat $< | [ Clean-up & rewrite ] > $@"
+	@cat $< \
 	  | sed -e 's/\(zyzyzy\|ZYZYZY\)/\1\/\` /' \
 	  | sed -e 's/^\(.*\)$$/----\1\*\1/' | tr '*' '\n' \
 	  | sed -e '/----/ s/î//g' \
@@ -333,19 +370,22 @@
 		-e 's/^\([-${CH}]\+\)\/\([${PRE}]*\)\([${SUFF}]\+\)\([${SUFF}]\)/\1\/\2\3\*\1\/\2\4/' \
 		-e 't START' \
 		-e 's/^\([-${CH}]\+\)\/\([${PRE}]\+\)\(\*\|$$\)/\1\/\*\1\/\2\3/'\
-	  |  tr '*' '\n' > munch2.tmp
-# This pipe produce a file containing the a line number of munch2.tmp and
+	  |  tr '*' '\n' > $@
+
+munch3.%: munch2.% ${LANGUAGE}.words.plain ${LANGUAGE}.munch.hash
+# This pipe produce a file containing the a line number of munch2 and
 # the frequency indicator for that line.  Note that the summation rule
 # is not the usual one.
-	PATH=$(PATHADDER):$$PATH; \
+	@echo "cat $< | [ Get line no and frequency ] > $@"
+	@PATH=$(PATHADDER):$$PATH; \
 	export PATH; \
-	cat munch2.tmp \
+	cat $< \
 	  | tr -d ' ' \
 	  | ispell -e -d ./${LANGUAGE}.munch.hash \
 	  | sed -e 's/^[-${CH}]\+ //' -e 's/î/-/g' \
 	  | awk --source '{i=0; while (i<NF) {i=i+1;print $$i,NR}}' \
 	  | sort \
-	  | join - ${LANGUAGE}.words \
+	  | join - ${LANGUAGE}.words.plain \
 	  | sed -e 's/\* //' \
 	  | cut -d ' ' -f2,3 \
 	  | sort -n \
@@ -360,15 +400,18 @@
 		if ($$i<5) {s=s+$$i} else {s = s + exp(exp(($$i+9)/15)-1)}}};\
 		if (s<=5) {t=s} else {t=-9+15*log(1+log(s))};\
 		print $$1, int(t)}' \
-	  > munch3.tmp
-# This pipe produce the file containing the munched list of words,
+	  > $@
+
+munched.%: munch2.% munch3.%
+# This pipe produces the file containing the munched list of words,
 # where the rare words we don't want are removed.  What we don't want
 # depends on the category of words, and is defined at the start of
 # this Makefile.
-	cat -n munch2.tmp \
-	  | join - munch3.tmp \
+	@echo "Collect data from $^ in $@"
+	@cat -n munch2.$* \
+	  | join - munch3.$* \
 	  | cut -d ' ' -f2,3 \
-	  | awk --re-interval --source ${$(subst munched.,CHOOSEFLAG,$@)} \
+	  | awk --re-interval --source ${CHOOSEFLAG$*} \
 	  | uniq \
 	  | tr -d ' ' \
 	  | sed -e '$$ p' -e '$$ D' -e ':START' -e '$$ ! N' \
@@ -387,62 +430,71 @@
 		if ($$i<5) {s=s+$$i} else {s = s + exp(exp(($$i+9)/15)-1)}}};\
 		if (s<=5) {t=s} else {t=-9+15*log(1+log(s))};\
 		print $$1, int(t)}' \
-	  | awk --re-interval --source ${$(subst munched.,CHOOSEROOT,$@)} \
+	  | awk --re-interval --source ${CHOOSEROOT$*} \
 	  | uniq \
 	  > $@
-#	Comment out the next line if you are debugging.
-	rm munch[123].tmp
-
 
-norsk.mch: forkort.txt $(patsubst %,munched.%,${CATHEGORIES}) $(AFFIXES)
 # Here we make the dictionary that is read by the ispell's builhash
 # program.  The main difficulty is to delete compound words with
 # frequency indicator less than COMPOUNDLIMIT accepted in controlled
 # compoundwords mode.
 
+%.comp1.mch: %.aff forkort.txt $(addprefix munched.,${CATHEGORIES})
 # First make a list of words with some compound flag, and a hash-file.
-	cat forkort.txt $(patsubst %,munched.%,${CATHEGORIES}) \
+	cat $(filter-out %.aff,$^) \
 	  | tr -d '\-0-9 ' \
 	  | grep "\/.*[z\\_\`]" \
-	  > comp1.tmp
-	$(BUILDHASH) comp1.tmp $(AFFIXES) comp.hash
+	  > $@
+
+%.comp.hash: %.comp1.mch
+	$(BUILDHASH) $< $(AFFIXES) $@
 
 # Make a list of candidates to be removed.  Exclude all words with
 # compound flags and those with frequency indicator bigger than
 # COMPOUNDLIMIT.  This could be improved.  One could insist that the
 # words forming a word that should be deleted are separated by a
 # hyphen at the correct point.  That would complicate things.
-
-	cat -n forkort.txt $(patsubst %,munched.%,${CATHEGORIES}) \
+%.comp2.mch: %.aff forkort.txt $(addprefix munched.,${CATHEGORIES})
+	cat -n $(filter-out %.aff,$^) \
 	  | grep -v "\/.*[z\\_\`]" \
 	  | awk --source '/-/ {if ($$3<${COMPOUNDLIMIT}) {print $$1,$$2,$$3}}' \
-	  > comp2.tmp
+	  > $@
+
 # Test which words are accepted by ispell.  Output is a list of line
 # numbers indicating the lines that can be removed from the munched
 # file.
+%.comp3.mch: %.comp2.mch %.comp.hash
 	PATH=$(PATHADDER):$$PATH; \
 	export PATH; \
-	cat comp2.tmp \
+	cat $< \
 	  | tr -d '\-0-9 ' \
-	  | ispell -e -d ./comp.hash \
+	  | ispell -e -d ./$*.comp.hash \
 	  | sed -e 's/$$/ xyxyxyxy/' \
-	  | ispell -l -d ./comp.hash \
+	  | ispell -l -d ./$*.comp.hash \
 	  | sed -e 's/xyxyxyxy/î/' \
 	  | tr '\nî' ' \n' \
-	  | paste comp2.tmp - \
+	  | paste $< - \
 	  | grep '	 $$' \
 	  | sed -e 's/ .*//' \
-	  > comp3.tmp
-	@echo Removing `cat comp3.tmp | wc -l` compound root words
+	  > $@
 # Remove all the line numbers that is found twice, and all words
 # containing xxxx and yyyy.  Those words didn't fit in in the munching,
 # and since it is few words I don't want to fiddle with them.
-	cat -n forkort.txt $(patsubst %,munched.%,${CATHEGORIES}) \
-	  | sort -n -m -s +0 -1  comp3.tmp - \
+
+norsk.mch: %.mch : %.comp3.mch forkort.txt $(addprefix munched.,${CATHEGORIES})
+	@echo Removing `cat $< | wc -l` compound root words
+	cat -n $(filter-out %.mch,$^) \
+	  | sort -n -m -s +0 -1 $< - \
 	  | sed -e '/^[0-9]\+$$/,/.*/ D' -e '/\(xxxx\|yyyy\)\// D' \
 	  | tr -d '\- 	0-9' \
 	  > $@
-	rm -f comp.hash comp[123].tmp*
+
+
+# Keep some of the  intermediate files from the above process to make
+# debugging easier, and because some of the steps take a LONG time
+.PRECIOUS: munch1.% munch2.% munch3.% %.comp1.mch %.comp2.mch %.comp3.mch
+
+
 
 # TODO:
 # If a rare word lies close to a common word, it might be wise to
@@ -456,11 +508,10 @@
 
 
 
-nynorsk.mch: norsk.words ny${AFFIXES}.munch
+nynorsk.mch: norsk.words.plain ny${AFFIXES}.munch
 	PATH=$(PATHADDER):$$PATH; \
 	export PATH; \
-	${CATNOHEADER} \
-	  | grep '\*' \
+	grep '\*' < $< \
 	  | sed -e 's/ .*//' \
 	  | tr -d '-' \
 	  | munchlist -v -l ny${AFFIXES}.munch \
@@ -468,13 +519,12 @@
 		-e '$$ p' -e '$$ d' -e P -e D \
 	  > $@ 
 
-words.norsk: norsk.words
+words.norsk: norsk.words.plain
 # Here is a rule to make a list of the most common Norwegian words.
 # Which words to include is defined at the top of this Makefile.  Such
 # a file is needed to make the word competition work for Norwegian.
 # Stupid spell checkers might also want such a file.
-	${CATNOHEADER} \
-	  | grep '[BANDS]$$' \
+	grep '[BANDS]$$' < $< \
 	  | tr -d '*' \
 	  | awk --re-interval --source ${WORDSFILTER} \
 	  | tr -d '\"-' \
@@ -482,19 +532,17 @@
 	  | sort -f \
 	  > $@
 
-words.nynorsk: norsk.words
+words.nynorsk: norsk.words.plain
 # No frequency information availiable yet for nynorsk.  So all we can
 # do is poick the words marked with a star.
-	${CATNOHEADER} \
-	  | grep '\*' \
+	grep '\*' < $<\
 	  | sed -e 's/ .*//' \
 	  > $@ 
 
 # Here is a target that picks words with given frequency.
-words.${LANGUAGE}.%: ${LANGUAGE}.words
-	${CATNOHEADER} \
-	  | grep '[BANDS]$$' \
-	  | grep  ' $(patsubst words.${LANGUAGE}.%,%,$@) ' \
+words.${LANGUAGE}.%: ${LANGUAGE}.words.plain
+	grep '[BANDS]$$' < $< \
+	  | grep  ' $* ' \
 	  | sed -e 's/ .*//' \
 	  | tr -d - \
 	  | grep -v '\(xxxx\|yyyy\|zyzyzy\)' \
@@ -505,11 +553,11 @@
 unpack:	norsk.words
 
 clean:
-	rm -f core *.hash *.stat *.cnt munch[123].tmp \
+	rm -f core *.hash *.stat *.cnt munch[123].* \
 	      ${DICTIONARY} ny${DICTIONARY} \
 	      ${AFFIXES} ny${AFFIXES} \
 	      ${AFFIXES}.munch ny${AFFIXES}.munch \
-	      comp[123].tmp*
+	      *.comp[123].* *myspell* munched.* core*
 
 #	The following target is used in the English makefile, and is
 #	required to be present in all other language Makefiles as
